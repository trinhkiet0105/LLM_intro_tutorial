# Model Serving Benchmarking

This repository contains scripts and tools for benchmarking model serving performance using the OpenAI endpoint. The goal is to measure and compare the efficiency, latency, and throughput of different model serving configurations.

## Table of Contents

- [Installation](#installation)
- [Serving](#usage) (if you don't have one already)
- [Benchmarking](#benchmarking)
- [Results](#results)

## Installation

To get started, clone the repository and install the required dependencies.

```bash
git clone https://github.com/trinhkiet0105/benchmark_vllm.git
cd benchmark_vllm.git
```


